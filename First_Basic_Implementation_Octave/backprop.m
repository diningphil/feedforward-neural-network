%% Initializationclear ; close all; clcTR = load("../../monks2prep.train");X = TR(:,2:end);% Add column of ones to X;m = size(X, 1); % Number of training examplesX = [ones(m,1) X];Y = TR(:,1);  %%%  TODO PREPROCESS Y (AND X EVENTUALLY). USE BACKPROP AS A FUNCTION AND CALL IT FROM A MAINn = size(X, 2); % Number of input units, also considering the biasmaxIter = 1000;TR_Err = 1:maxIter;threshold = 2.0; % 2%j = 6; % Number of hidden units k = 2; % Number of output unitsa = 1;eta = 0.1;% lambda = 0; TODO add regularization% Theta is a matrix of weights. Theta(a,b) is the weight with destination in unit "a" % and source in unit "b"Theta1 = rem(randn(j,n), 0.7); % j destinations, i+1(bias) sourcesTheta2 = rem(randn(k,j+1), 0.7); % k destinations, j+1(bias) sourcesout = zeros(k, 1);%% Compute actual output errorErr_tot = 0;[O, net_t, o] = feedforwardVect(X, Theta1, Theta2, 1, a);[Err_tot, Delta] = computeCost(O, Y);nIter = 0;while ( ((Err_tot/m)*100 > threshold) && nIter < maxIter)  nIter = nIter + 1;  D1 = zeros(j, n);  D2 = zeros(k, j+1);     for p=1:m % for each pattern    delta_out = zeros(k,1);    [output, net_t, o] = feedforward(X(p,:), Theta1, Theta2, a);       for t=1:k % for each output unit       % opj in the theory would be output(t)              d = Y(p,:)';                    [Ep, delta] = computeError(output, d);             delta_out(t) = delta(t)*sigmoidGradient(a, net_t(t));                for i=1:j+1 % for each weight Wti of this layer         o_i = o(i);         D2(t,i) = D2(t,i) + eta*delta_out(t)*o_i;        end    end                 %% Consider Theta2 without the first column (info about bias)    Theta2noBias = Theta2(:, 2:end);    delta_hid = zeros(j,1);    for t=1:j % for each hidden unit       net_h = Theta1(t,:)*X(p,:)';              delta_hid = (Theta2noBias(:,t)'*delta_out)*sigmoidGradient(a, net_h);              for i=1:n % for each weight Wti of this layer         out_i = X(p,i);         D1(t,i) = D1(t,i) + eta*delta_hid*out_i;       end     end  end    Theta1 += D1;  Theta2 += D2;  %%%%%%%%% END %%%%%%%%%%%%  % compute new output error  Err_tot = 0;  [O, net_t, o] = feedforwardVect(X, Theta1, Theta2, 1, a);  [Err_tot, Delta] = computeCost(O, Y);  TR_Err(nIter) = Err_tot; % prints Err_tot at each iterationend% Show results  plot(1:nIter, 100*TR_Err(1:nIter)/m);  disp(Err_tot);  disp(Err_tot/m);        